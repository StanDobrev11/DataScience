get_ipython().run_line_magic("matplotlib", " inline")


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression, LogisticRegression





x = np.linspace(-3, 5, 10)
y = 2 * x + 3


plt.plot(x, y) # this is the model
plt.scatter(x, y, c='r') # this is the data
plt.show()





x = np.linspace(-3, 5, 1000)
y = 2 * x + 3


plt.scatter(x, y, c='r', s=0.1) # this is the data
plt.xlabel('x')
plt.ylabel('y')
plt.show()


y_noise = np.random.normal(loc=0, scale=0.5, size=len(x)) # variance


y_result = y + y_noise





plt.scatter(x, y_result, c='r', s=0.1)
plt.xlabel('x')
plt.ylabel('y')
plt.show()





y = y_result # data including random error





a = 8
b = 2

model_x = np.linspace(np.min(x), np.max(x), 5)
model_y = a * model_x + b


plt.plot(model_x, model_y)
plt.show()





def plot_predictions(x, y, a, b):

    predictions = a * x + b
    
    plt.plot(x, predictions, label='Model')
    plt.scatter(x, y, c='r', s=0.1, label='Data')
    
    plt.xlabel('x')
    plt.ylabel('y')

    plt.title('Model against expected data')
    plt.legend()
    plt.show()


plot_predictions(x, y, 8, 2)


plot_predictions(x, y, -2, 1)





plot_predictions(x, y, 2, 1)





def compute_distances_mae(x, y, a, b):
    prediction = a * x + b
    distances = np.abs(y - prediction)
    total_distance = np.mean(distances) # mean absolute error MAE
    return total_distance


compute_distances(x, y, -2, 1)


compute_distances(x, y, 2, 1)


compute_distances(x, y, 8, 2)


def compute_distances_mse(x, y, a, b):
    """ this is also solution """
    prediction = a * x + b
    distances = (y - prediction) ** 2
    total_distance = np.mean(distances) # mean squared error MSE
    return total_distance





def compute_gradient(x, y, a, b):
    prediction = a * x + b
    a_gradient = -2 / len(x) * np.sum(x * (y - prediction))
    b_gradient = -2 / len(x) * np.sum(y - prediction)
    return np.array([a_gradient, b_gradient])


compute_gradient(x, y, 5, 1)





0.01 * compute_gradient(x, y, 5, 1)





a, b = 5, 1
learning_rate = 0.01
a = a - learning_rate * compute_gradient(x, y, a, b)[0]
b = b - learning_rate * compute_gradient(x, y, a, b)[1]


a, b


compute_distances_mse(x, y, a, b)


def iterative_approach(n, x, y, a, b):
    for step in range(n + 1):
        result = compute_distances_mse(x, y, a, b)
        a = a - learning_rate * compute_gradient(x, y, a, b)[0]
        b = b - learning_rate * compute_gradient(x, y, a, b)[1]
    return result, a, b


result = iterative_approach(1000, x, y, 5, 1)
print(result)


a, b = result[1], result[2]


plot_predictions(x, y, a, b)


model = LinearRegression()
model.fit(x, y)


x = x.reshape(-1, 1)


model.fit(x, y)


model.coef_


model.intercept_


a, b


model.predict(x)





def sigmoid(x):
    return 1 / (1 + np.ext(-x))


y = sigmoid(a * x + b)


x = np.linspace(-5, 5, 20)
y = (x >= 3).astype(int)


classifyer = LogisticRegression()


classifyer.fit(x.reshape(-1, 1), y)


classifyer.predict(x.reshape(-1, 1))



