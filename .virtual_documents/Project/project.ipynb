get_ipython().run_line_magic("matplotlib", " inline")


import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from scipy.interpolate import griddata
from scipy.stats import gaussian_kde, pearsonr, spearmanr, ttest_ind
from scipy.spatial.distance import euclidean, cdist

from sklearn.cluster import DBSCAN
from sklearn.metrics.pairwise import haversine_distances





def get_dataframe(path):
    """
    Reads a CSV file into a Pandas DataFrame and converts the index to datetime format.

    Parameters:
        path (str): The file path of the CSV to read.
    Returns:
        DataFrame: A Pandas DataFrame with the index converted to datetime.
    """
    df = pd.read_csv(path, index_col=0)
    df.index = pd.to_datetime(df.index)

    return df


def plot_equatorial_pacific(path, cond_name, plot_type='cnt', vmin=None, vmax=None):
    """
    Plots sequential months of Sea Surface Temperature (SST) data for the equatorial Pacific Ocean, 
    with each month's data displayed on a separate subplot. The user can choose between a contour map 
    or scatter plot for visualization.

    Parameters:
        path (str): Path to the CSV file containing SST data.
        cond_name (str): The name of the event to be plotted (e.g., "El Niño", "La Niña").
        plot_type (str): The type of plot to create, either contour map ['cnt'] (default) or scatter plot ['sct'].
        vmin (float, optional): The minimum scale value for the temperature color range. Defaults to the minimum SST value in the data.
        vmax (float, optional): The maximum scale value for the temperature color range. Defaults to the maximum SST value in the data.
    Returns:
        None: Displays the subplots showing SST data for each month.
    """
    df = get_dataframe(path)

    grouped_df = df.groupby(df.index)

    # Determine the number of subplots (one for each unique date)
    subplot_count = len(grouped_df)

    # Create subplots in a single row
    fig, axs = plt.subplots(1, subplot_count, figsize=(15 * subplot_count, 8))

    # If only one subplot, axs will not be an array, so we convert it to one
    if subplot_count == 1:
        axs = [axs]

    # Determine the common range for the color scale
    all_sst_values = df['sst'].values

    if vmin is None or vmax is None:
        vmin, vmax = np.min(all_sst_values), np.max(all_sst_values)

    for i, (date, data) in enumerate(grouped_df):

        if plot_type == 'sct':
            subplot = axs[i].scatter(data.lon, data.lat, c=data.sst, cmap='jet', alpha=0.7, s=150, vmin=vmin, vmax=vmax)

        else:
            lon_grid = np.linspace(data.lon.min(), data.lon.max(), 100)
            lat_grid = np.linspace(data.lat.min(), data.lat.max(), 100)
            lon_grid, lat_grid = np.meshgrid(lon_grid, lat_grid)
            sst_grid = griddata((data.lon, data.lat), data.sst, (lon_grid, lat_grid), method='linear')

            subplot = axs[i].contourf(lon_grid, lat_grid, sst_grid, cmap='jet', levels=20, vmin=vmin, vmax=vmax)

        fig.colorbar(subplot, ax=axs[i], label='Temperature')

        x_tick = np.arange(130, 290, 10)
        x_label = [f'{x}°E' if x <= 180 else f'{360 - x}°W' for x in x_tick]

        y_tick = np.arange(-20, 25, 5)
        y_label = [f'{np.abs(x)}°S' if x < 0 else f'{np.abs(x)}°N' for x in y_tick]

        axs[i].add_patch(plt.Rectangle((190, -5), 50, 10, linewidth=2, edgecolor='red', facecolor='none'))

        axs[i].axhline(y=0)

        axs[i].set_xticks(ticks=x_tick)
        axs[i].set_xticklabels(labels=x_label)

        axs[i].set_yticks(ticks=y_tick)
        axs[i].set_yticklabels(labels=y_label)

        axs[i].set_xlim(130, 280)
        axs[i].set_ylim(-20, 20)
        axs[i].set_xlabel('Longitude')
        axs[i].set_ylabel('Latitude')
        axs[i].set_title(f'{cond_name} SST for {pd.to_datetime(date).strftime("%B %Y")}')

    plt.tight_layout()
    plt.show()


plot_equatorial_pacific(path='data/csv_ready/elnino_2015.csv', cond_name='El Niño Period', vmin=20, vmax=35)


plot_equatorial_pacific('data/csv_ready/neutral_2012.csv', 'Neutral Period', vmin=20, vmax=35)


plot_equatorial_pacific('data/csv_ready/lanina_2010.csv', 'La Niña Period', vmin=20, vmax=35)


def get_dataframes():
    """
    Returns a list of base dataframes
    """
    la_nina = get_dataframe('data/csv_ready/lanina_2010.csv')
    neutral = get_dataframe('data/csv_ready/neutral_2012.csv')
    el_nino = get_dataframe('data/csv_ready/elnino_2015.csv')

    return [el_nino, neutral, la_nina]

def get_colors(index=None):
    """
    Returns a list of colors or a specific color based on the provided index.

    Parameters:
        index (int, optional): The index corresponding to the color. If None, returns the full list of colors.
                               Defaults to None.
    Returns:
        list or str: A list of colors ['r', 'g', 'b'] if index is None, or a specific color if an index is provided.
    """
    colors = ['r', 'g', 'b']
    if index is None:
        return colors
    return colors[index]

def get_ocean_area_label(index=None):
    """
    Returns a list of ocean area labels or a specific label based on the provided index.

    Parameters:
        index (int, optional): The index corresponding to the ocean area label. If None, returns the full list of labels.
                               Defaults to None.
    Returns:
        list or str: A list of ocean area labels ['NW', 'Central and NE'] if index is None, or a specific label 
                     if an index is provided.
    """
    ocean_area = ['NW', 'Central and NE']
    if index is None:
        return ocean_area
    return ocean_area[index]

def get_phase_label(phase=None):
    """
    Returns a list of ENSO phase labels or a specific label based on the provided phase index.

    Parameters:
        phase (int, optional): The index corresponding to the ENSO phase (-1 for La Niña, 0 for Neutral, 1 for El Niño).
                               If None, returns the full list of labels. Defaults to None.
    Returns:
        list or str: A list of ENSO phase labels ['La Niña', 'Neutral', 'El Niño'] if phase is None, 
                     or a specific label if a phase index is provided.
    """
    labels = ['La Niña', 'Neutral', 'El Niño']
    if phase is None:

        return labels
    return labels[phase]

def get_enso_colors(phase=None):
    """
    Returns the color corresponding to a given ENSO phase key, or the entire color mapping dictionary if no phase is provided.

    Parameters:
        phase (int, optional): The key representing the ENSO phase (-1 for La Niña, 0 for Neutral, 1 for El Niño).
                               If None, returns the entire color mapping dictionary. Defaults to None.
    Returns:
        str or dict: The color associated with the given phase ('blue' for La Niña, 'green' for Neutral, 'red' for El Niño),
                     or the full dictionary of ENSO colors if no phase is provided.
    """
    colors_mapper = {-1: 'blue', 0: 'green', 1: 'red'}
    return colors_mapper.get(phase, colors_mapper)

def get_enso_months(index=None):
    """
    Returns a list of ENSO-related months or a specific month based on the provided index.

    Parameters:
        index (int, optional): The index corresponding to a specific month. If None, returns the full list of months.
                               Defaults to None.
    Returns:
        list or str: A list of months ['October', 'November', 'December', 'January'] if index is None,
                     or a specific month if an index is provided.
    """
    months = ['October', 'November', 'December', 'January']

    if index is None:
        return months

    return months[index]

def get_cmaps(key=None):
    """
    Returns the colormap corresponding to a given ENSO phase key, or the entire colormap dictionary if no key is provided.

    Parameters:
        key (int, optional): The key representing the ENSO phase (-1 for La Niña, 0 for Neutral, 1 for El Niño). 
                             If None, returns the entire colormap dictionary. Defaults to None.
    Returns:
        str or dict: The colormap name associated with the given key ('Blues' for La Niña, 'Greens' for Neutral, 'Reds' for El Niño),
                     or the full dictionary of colormaps if no key is provided.
    """
    cmaps = {-1: 'Blues', 0: 'Greens', 1: 'Reds'}
    return cmaps.get(key, cmaps)

def get_phase_names(key=None):
    """
    Returns the name of the ENSO phase corresponding to a given key, or the entire phase dictionary if no key is provided.

    Parameters:
        key (int, optional): The key representing the ENSO phase (-1 for La Niña, 0 for Neutral, 1 for El Niño).
                             If None, returns the entire phase dictionary. Defaults to None.
    Returns:
        str or dict: The name of the ENSO phase ('La Niña', 'Neutral', or 'El Niño') corresponding to the given key,
                     or the full dictionary of phase names if no key is provided.
    """
    phases = {-1: 'La Niña', 0: 'Neutral', 1: 'El Niño'}
    return phases.get(key, phases)
    
def plot_sst_difference(dfs):
    """
    Plots the Sea Surface Temperature (SST) difference for different ENSO phases over specific months.
    
    Parameters:
        dfs (list of DataFrames): A list of DataFrames containing SST data for different ENSO phases.
    Returns:
        None: Displays a line plot showing the SST differences for each ENSO phase over the months of October to January.
    """

    for i, df in enumerate(dfs):
        sst = df.groupby(df.index).sst.mean()
        plt.plot(get_enso_months(), sst, c=get_colors(i), label=get_phase_label(i))
    
    plt.ylim(26, 29)
    
    plt.legend()
    plt.xlabel('Months')
    plt.ylabel('SST in deg C')
    plt.title('Difference in the SST between El Niño, La Niña and Neutral Periods')
    
    plt.show()


plot_sst_difference(get_dataframes())

















# load various data. in order to read the data only once, the code is not grouped in a function
oni_table = pd.read_csv('data/csv_ready/oni_table.csv', index_col=0)
oni_temp = pd.read_csv('data/csv_ready/oni_temp.csv', index_col=0)
oni_table.index = pd.to_datetime(oni_table.index)
enso_phase = oni_table.groupby(oni_table.index.year)['enso'].apply(lambda x: x.unique()[0])

jma = pd.read_csv('data/csv_ready/jma_td.csv', index_col=0)
jma.index = pd.to_datetime(jma.index)
frequency_jma = jma.groupby(jma.index.year)['name'].nunique()
frequency_jma = pd.merge(frequency_jma, enso_phase, on='date')
frequency_jma.columns = ['frequency', 'enso']

nhc = pd.read_csv('data/csv_ready/ne_pacific_td.csv', index_col=0)
nhc.index = pd.to_datetime(nhc.index)
frequency_nhc = nhc.groupby(nhc.index.year)['name'].nunique()
frequency_nhc = pd.merge(frequency_nhc,enso_phase, on='date')
frequency_nhc.columns = ['frequency', 'enso']

nhc_cp = nhc[nhc.basin == 'CP']
frequency_nhc_cp = nhc_cp.groupby(nhc_cp.index.year)['name'].nunique()
frequency_nhc_cp = pd.merge(frequency_nhc_cp,enso_phase, on='date')
frequency_nhc_cp.columns = ['frequency', 'enso']

nhc_ep = nhc[nhc.basin == 'EP']
frequency_nhc_ep = nhc_ep.groupby(nhc_ep.index.year)['name'].nunique()
frequency_nhc_ep = pd.merge(frequency_nhc_ep,enso_phase, on='date')
frequency_nhc_ep.columns = ['frequency', 'enso']

frequency_tables = [
    ('NW', frequency_jma), 
    ('Central', frequency_nhc_cp), 
    ('NE', frequency_nhc_ep)]

dfs_freq = [frequency_jma, frequency_nhc]


def plot_yearly_frequency(dfs):
    """
    Plots the yearly frequency of tropical depressions for different Pacific regions (NW, Central, NE)
    based on ENSO phases (La Niña, Neutral, El Niño). Each ENSO phase is represented by a different color, 
    and the frequency is displayed in a bar chart for each year.

    Parameters:
        dfs (list of tuples): A list of tuples where each tuple contains:
                              - A string representing the region (e.g., 'NW', 'Central', 'NE').
                              - A DataFrame with columns ['frequency', 'enso'] where 'frequency' is the number 
                                of tropical depressions in a given year, and 'enso' is the corresponding ENSO phase.
    Returns:
        None: Displays a bar plot for each region with ENSO phases represented by different colors.
    """
    labels = get_phase_label()
    colors = get_colors()
    
    fig, axs = plt.subplots(1, 3, figsize=(30, 8))
    
    for i, table in enumerate(dfs):
        for year, freq, enso in zip(table[1].index, table[1].frequency, table[1].enso):
            axs[i].bar(year, freq, color=get_enso_colors(enso))
        
        # Create the legend for ENSO phases
        rectangles = [plt.Rectangle((0,0),1,1, color=color) for color in colors]
        axs[i].legend(rectangles, labels, title='ENSO Phase', loc='upper left')
        
        axs[i].set_title(f'Frequency of Tropical Depressions, originating in the {table[0]} Pacific, by Year')
        axs[i].set_xlabel('Year')
        axs[i].set_ylabel('Number of Tropical Depressions')
        axs[i].set_xlim(1950, 2024)
        axs[i].set_ylim(0, 37)
    
    plt.show()


plot_yearly_frequency(frequency_tables)


def add_value_labels(ax, bars):
    """
    Adds value labels on top of each bar in a bar plot.

    Parameters:
        ax (Axes): The Matplotlib Axes object containing the bars.
        bars (BarContainer): The container of bars (from a bar plot) to annotate with values.
    Returns:
        None: Adds annotations to the plot directly.
    """
    for bar in bars:
        height = bar.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3),
                    textcoords="offset points",
                    ha='center', va='bottom')

def plot_mean_frequency(dfs):
    """
    Plots the mean frequency of tropical depressions by ENSO phase for multiple datasets 
    and different Pacific Ocean regions. The mean frequency is calculated for each ENSO phase.

    Parameters:
        dfs (list of DataFrames): A list of DataFrames where each DataFrame contains the frequency 
                                  of tropical depressions and ENSO phase for a specific region.
    Returns:
        None: Displays a bar plot showing the mean frequency of tropical depressions by ENSO phase 
              for different regions of the Pacific.
    """
    labels = get_phase_label()
    ocean_area = get_ocean_area_label()
    
    mean_data = [[x for x in df.groupby(['enso']).frequency.mean()] for df in dfs]
    x_axis = np.arange(len(labels))

    # set the width of the bars
    width = 0.20

    fig, ax = plt.subplots(figsize=(10, 8))

    for i, df_data in enumerate(mean_data):
        x_values = (x_axis - width/2) if i == 0 else (x_axis + width/2)
        bars = ax.bar(x_values, df_data, width, label=f'{ocean_area[i]} Pacific')
        add_value_labels(ax, bars)
        
    ax.set_xlabel('ENSO Phase')
    ax.set_ylabel('Mean Frequency of Tropical Depressions')
    ax.set_title('Mean Frequency of Tropical Depressions by ENSO Phase')
    ax.set_xticks(x_axis)
    ax.set_xticklabels(labels)
    ax.legend()
    
    plt.show()


plot_mean_frequency(dfs_freq)





# Grouping by year and finding max wind and min press
jma_max_wind = jma.groupby([jma.index.year]).max_wind_kn.max()
nhc_max_wind = nhc.groupby([nhc.index.year]).max_wind_kn.max()

jma_min_press = jma.groupby([jma.index.year]).min_pressure_mBar.min()
nhc_min_press = nhc.groupby([nhc.index.year]).min_pressure_mBar.min()

jma_max_wind = pd.merge(jma_max_wind, enso_phase, on='date')
jma_max_wind.max_wind_kn = jma_max_wind.max_wind_kn.apply(lambda x: None if x == 0 else x)
jma_max_wind = jma_max_wind.dropna()
nhc_max_wind = pd.merge(nhc_max_wind, enso_phase, on='date')

jma_min_press = pd.merge(jma_min_press, enso_phase, on='date')
nhc_min_press = pd.merge(nhc_min_press, enso_phase, on='date')
nhc_min_press.min_pressure_mBar = nhc_min_press.min_pressure_mBar.apply(lambda x: None if x < 0 else x)
nhc_min_press = nhc_min_press.dropna()


# statistics
def extract_stats(df):
    df = df.groupby(['enso']).describe().T
    df = df.reset_index()
    df = df.drop(columns='level_0')
    df = df.pivot_table(columns='level_1')

    return df
    
array_of_data = [jma_max_wind, nhc_max_wind, jma_min_press, nhc_min_press]
jma_max_wind_stats = extract_stats(jma_max_wind)
nhc_max_wind_stats = extract_stats(nhc_max_wind)
jma_min_press_stats = extract_stats(jma_min_press)
nhc_min_press_stats = extract_stats(nhc_min_press)


# function to plot the boxplot and tables
def plot_boxplot_and_table(dataset_array, tables_array, col_name, title, ylim=None):
    """
    Plots boxplots for a specified column across different ENSO phases (La Niña, Neutral, El Niño) 
    for different Pacific regions, along with corresponding statistical tables. 

    Parameters:
        dataset_array (list of DataFrames): A list of DataFrames where each DataFrame contains data for a specific Pacific region.
        tables_array (list of DataFrames): A list of DataFrames containing statistical summary data (mean, std, etc.) 
                                           for each ENSO phase corresponding to the datasets.
        col_name (str): The column name for which to create the boxplots (e.g., wind speed, pressure).
        title (str): The title for the boxplots.
        ylim (tuple, optional): A tuple specifying the y-axis limits for the boxplots (e.g., (0, 50)). 
                                Defaults to None (no limit).

    Returns:
        None: Displays the boxplots and corresponding tables for the different Pacific regions.
    """
    labels = get_phase_label()
    ocean_area = get_ocean_area_label()
    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 12))
    
    for i, df in enumerate(dataset_array):
        axs[0][i].boxplot([df[df['enso'] == -1][col_name],
                         df[df['enso'] == 0][col_name],
                         df[df['enso'] == 1][col_name]],
                         labels=labels)
        axs[0][i].set_title(f'{title} by ENSO Phase for {ocean_area[i]} Pacific')
        axs[0][i].set_xlabel('ENSO Phase')
        axs[0][i].set_ylabel(title)
        if not ylim is None:
            axs[0][i].set_ylim(ylim)
    
    for i, dt in enumerate(tables_array):
        axs[1][i].axis('tight')
        axs[1][i].axis('off')
        axs[1][i].table(cellText=dt.values.round(1),
                     colLabels=dt.columns,
                     rowLabels=labels,
                     cellLoc='center', loc='center')
    
    plt.tight_layout()
    plt.show()


values = nhc_max_wind.max_wind_kn[nhc_max_wind.enso == 1]
pdf = gaussian_kde(values)

# Generate a range of values for the x-axis
x = np.linspace(min(values), max(values), 1000)

# Plot the PDF
plt.plot(x, pdf(x), label='PDF of Values')

# Add labels and title
plt.xlabel('Value')
plt.ylabel('Density')
plt.title('PDF of Values from DataFrame')

# Show the plot
plt.legend()
plt.grid(True)
plt.show()


sns.kdeplot(values, bw_adjust=0.5, fill=True, label='PDF of Values')


nhc_max_wind.max_wind_kn[nhc_max_wind.enso == 0]


nhc_max_wind.max_wind_kn[nhc_max_wind.enso == -1].skew()


# Boxplot for Maximum Wind Speed
dataset_boxplot = [jma_max_wind, nhc_max_wind]
dataset_table = [jma_max_wind_stats, nhc_max_wind_stats]

plot_boxplot_and_table(dataset_boxplot, dataset_table, 'max_wind_kn', 'Maximum Wind Speed', ylim=(70, 190))





# Boxplot for Minimum Central Pressure
dataset_boxplot = [jma_min_press, nhc_min_press]
dataset_table = [jma_min_press_stats, nhc_min_press_stats]

plot_boxplot_and_table(dataset_boxplot, dataset_table, 'min_pressure_mBar', 'Minimum Central Pressure (mBar)', ylim=(865, 975))





enso_phase_dt = enso_phase.copy()
enso_phase_dt.index = pd.to_datetime(enso_phase.index.astype(str))

merged = pd.merge(jma, enso_phase_dt, left_on=jma.index.year, right_on=enso_phase_dt.index.year, how='left')
merged = merged.set_index(jma.index)
jma_enso = merged.drop(columns='key_0')

merged = pd.merge(nhc, enso_phase_dt, left_on=nhc.index.year, right_on=enso_phase_dt.index.year, how='left')
merged = merged.set_index(nhc.index)
nhc_enso = merged.drop(columns='key_0')

gdf = pd.read_csv('data/csv_ready/gdf_pacific.csv')


def plot_td_density():
    """ 
    Plots the density of Tropical Depressions (TDs) for different phases of ENSO (El Niño, La Niña, Neutral) 
    across the North Pacific Ocean. The function creates density plots using kernel density estimation (KDE) 
    for each phase and visualizes them on a subplot.
    """
    cmaps = get_cmaps()
    phases = get_phase_names()

    datasets = [jma_enso, nhc_enso]
    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(20 * 3, 8))

    for idx, i in enumerate(range(-1, 2, 1)):
        for df in datasets:
            subset = df[df.enso == i]  
            sns.kdeplot(x=subset['lon'], y=subset['lat'], fill=True, cmap=cmaps[i], bw_adjust=0.8, ax=axs[idx])

        axs[idx].scatter(gdf.lon, gdf.lat, s=0.5, color='black')
        
        x_tick = np.arange(100, 300, 10)
        x_label = [f'{x}°E' if x <= 180 else f'{360 - x}°W' for x in x_tick]
        y_tick = np.arange(-20, 70, 10)
        y_label = [f'{np.abs(x)}°S' if x < 0 else f'{np.abs(x)}°N' for x in y_tick]
        axs[idx].set_xticks(ticks=x_tick)
        axs[idx].set_xticklabels(labels=x_label)
        axs[idx].set_yticks(ticks=y_tick)
        axs[idx].set_yticklabels(labels=y_label)
        
        axs[idx].set_title(f'Density of Tropical Depressions for {phases[i]} phase')
        axs[idx].set_xlabel('Longitude')
        axs[idx].set_ylabel('Latitude')
        
    plt.tight_layout()
    plt.show()
    

def haversine(lon1, lat1, lon2, lat2):
    """
    Calculate the great-circle distance between two points on the Earth 
    specified in decimal degrees using the Haversine formula.
    
    Parameters:
        lon1, lat1: Longitude and latitude of the first point.
        lon2, lat2: Longitude and latitude of the second point.
    
    Returns:
        Distance between the two points in kilometers.
    """
    # Convert decimal degrees to radians
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])
    
    # Haversine formula
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))
    
    # Radius of Earth in kilometers (mean radius)
    R = 6371.0088
    return R * c

def haversine_(lon1, lat1, lon2, lat2):
    # Convert all points to radians
    first_points_rad = np.radians(np.vstack([lon1, lat1]).T)  # (N, 2) array where N is the number of points
    second_point_rad = np.radians([lon2, lat2])  # Single point in radians

    # Compute Haversine distance between each point and the single grid point
    result = haversine_distances(first_points_rad, [second_point_rad])  # (N, 1) array of distances

    # Return distances in kilometers
    return result.flatten() * 6371.0088  # Earth's radius in kilometers

def compute_kde_values(df, phase, method, gridsize=100, bandwidth=0.1):

    # Subset data for the specific ENSO phase
    subset = df[df.enso == phase]
    
    # Extract longitude and latitude values
    lon_vals = subset['lon'].values
    lat_vals = subset['lat'].values
    
    # Define grid boundaries in degrees
    lon_min, lon_max = 100, 300
    lat_min, lat_max = -20, 70
    lon_grid, lat_grid = np.linspace(lon_min, lon_max, gridsize), np.linspace(lat_min, lat_max, gridsize)
    lon_grid, lat_grid = np.meshgrid(lon_grid, lat_grid)
    
    if method == 'haversine':
        # Initialize KDE grid
        kde_values = np.zeros(lon_grid.shape)
        
        # Compute KDE using Haversine distance for each grid point
        for i in range(gridsize):
            for j in range(gridsize):
                # Calculate the distance from each data point to the grid point
                distances = haversine_(lon_vals, lat_vals, lon_grid[i, j], lat_grid[i, j])         
                # Apply Gaussian kernel to distances and sum
                kde_values[i, j] = np.sum(np.exp(-0.5 * (distances / bandwidth)**2))
        
        # Normalize KDE values
        kde_values /= (bandwidth * np.sqrt(2 * np.pi)) * len(lon_vals)

    elif method == 'euclidean':
        kde = gaussian_kde(np.vstack([subset['lon'], subset['lat']]))
        kde_values = kde(np.vstack([lon_grid.ravel(), lat_grid.ravel()])).reshape(gridsize, gridsize)
    
    return lon_grid, lat_grid, kde_values
    
def plot_td_density_difference(method):
    """ 
    Plots the density differences of Tropical Depressions (TDs) for different ENSO phases 
    (El Niño, La Niña, Neutral) across the North Pacific Ocean. It computes the differences 
    between KDE values for each phase and creates visual comparisons using heatmaps. 
    The function shows the results for both NW Pacific and NE/Central Pacific regions.
    """
    kde_values_jma = {phase: compute_kde_values(jma_enso, phase, method)[2] for phase in range(-1, 2)}
    kde_values_nhc = {phase: compute_kde_values(nhc_enso, phase, method)[2] for phase in range(-1, 2)}

    # Subtract KDE values to create difference maps for each region
    diff_maps_jma = {
        'El Niño - La Niña (NW Pacific)': kde_values_jma[1] - kde_values_jma[-1],
        'Neutral - La Niña (NW Pacific)': kde_values_jma[0] - kde_values_jma[-1],
        'Neutral - El Niño (NW Pacific)': kde_values_jma[0] - kde_values_jma[1]
    }
    
    diff_maps_nhc = {
        'El Niño - La Niña (NE/Central Pacific)': kde_values_nhc[1] - kde_values_nhc[-1],
        'Neutral - La Niña (NE/Central Pacific)': kde_values_nhc[0] - kde_values_nhc[-1],
        'Neutral - El Niño (NE/Central Pacific)': kde_values_nhc[0] - kde_values_nhc[1]
    }

    fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(20, 12))
    
    for i, diff_dt in enumerate([diff_maps_jma, diff_maps_nhc]):
        for idx, (title, diff_map) in enumerate(diff_dt.items()):
            im = axs[i, idx].imshow(diff_map, extent=[100, 300, -20, 70], origin='lower', cmap='coolwarm')
            axs[i, idx].set_title(title)
            axs[i, idx].scatter(gdf.lon, gdf.lat, s=0.5, color='black')
            
            x_tick = np.arange(100, 300, 25)
            x_label = [f'{x}°E' if x <= 180 else f'{360 - x}°W' for x in x_tick]
            y_tick = np.arange(-20, 70, 20)
            y_label = [f'{np.abs(x)}°S' if x < 0 else f'{np.abs(x)}°N' for x in y_tick]
            axs[i, idx].set_xticks(ticks=x_tick)
            axs[i, idx].set_xticklabels(labels=x_label)
            axs[i, idx].set_yticks(ticks=y_tick)
            axs[i, idx].set_yticklabels(labels=y_label)
            
            axs[i, idx].set_xlabel('Longitude')
            axs[i, idx].set_ylabel('Latitude')
    
    plt.tight_layout()
    plt.show()


# plot_td_density()





plot_td_density_difference(method='euclidean')











# Define the Haversine function to apply on arrays
def haversine_array(latlon1, latlon2):
    """
    Compute the Haversine distance between two sets of points.
    
    Parameters:
        latlon1 (array-like): An array of (latitude, longitude) pairs.
        latlon2 (array-like): Another array of (latitude, longitude) pairs.
        
    Returns:
        distances (ndarray): An array of distances between each pair of points.
    """
    # Radius of Earth in kilometers
    R = 6371
    
    # Convert to radians
    lat1, lon1 = np.radians(latlon1[:, 0]), np.radians(latlon1[:, 1])
    lat2, lon2 = np.radians(latlon2[:, 0]), np.radians(latlon2[:, 1])

    # Reshape to allow broadcasting of arrays for pairwise distance calculations
    lat1 = lat1[:, np.newaxis]  # Shape (N, 1)
    lon1 = lon1[:, np.newaxis]  # Shape (N, 1)
    
    # Differences in coordinates
    dlat = lat2 - lat1
    dlon = lon2 - lon1

    # Haversine formula components
    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))
    
    # Distance in kilometers
    distances = R * c
    return distances

def run_dbscan(df, method, eps, min_samples):
    """ 
    Runs the DBSCAN clustering algorithm on a dataset of geographical coordinates (longitude and latitude). 
    It returns the clusters formed and the corresponding labels for each point.
    
    Parameters:
        df (DataFrame): The dataset containing 'lon' and 'lat' columns.
        eps (float): The maximum distance between two samples for them to be considered as neighbors (default: 1.0).
        min_samples (int): The minimum number of samples required to form a cluster (default: 5).
    
    Returns:
        clusters (list of arrays): A list of clusters, where each cluster contains the coordinates of points.
        labels (ndarray): An array of labels for each point (-1 for noise, integers for cluster membership).
    """
    if method == 'haversine':
        # Convert lat/lon from degrees to radians
        coords = np.radians(df[['lon', 'lat']].values)
        # The eps parameter in DBSCAN must be in radians when using Haversine distance.
        # To convert eps from kilometers to radians, divide by Earth's radius (6371.0088 km).
        eps_radians = eps / 6371.0088
        # Run DBSCAN with Haversine metric
        db = DBSCAN(eps=eps_radians, min_samples=min_samples, metric='haversine').fit(coords)
        labels = db.labels_
        unique_labels = set(labels)
    elif method == 'euclidean':
        # Extract clusters, exclude noise (-1)
        coords = df[['lon', 'lat']].values
        db = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean').fit(coords)
        labels = db.labels_
        unique_labels = set(labels)
        
    clusters = [coords[labels == label] for label in unique_labels if label != -1]  # Exclude noise (-1)
    return clusters, labels

def compute_cluster_metrics(clusters):
    """ 
    Computes metrics for a set of clusters, including the number of clusters, average cluster size, 
    and the centroids of the clusters.
    
    Parameters:
        clusters (list of arrays): A list of clusters, where each cluster contains the coordinates of points.
    
    Returns:
        num_clusters (int): The number of clusters.
        average_size (float): The average size (number of points) of the clusters.
        centroids (list of arrays): A list of centroid coordinates for each cluster.
    """
    num_clusters = len(clusters)
    cluster_sizes = [len(cluster) for cluster in clusters]
    average_size = np.mean(cluster_sizes)
    centroids = [np.mean(cluster, axis=0) for cluster in clusters]
    return num_clusters, average_size, centroids


def compare_clusters(centroids1, centroids2, method):
    """ 
    Compares two sets of cluster centroids by computing the mean, median, minimum, and maximum Haversine distances 
    between centroids in the two sets.
    
    Parameters:
        centroids1 (list of arrays): The centroids of the first set of clusters.
        centroids2 (list of arrays): The centroids of the second set of clusters.
    
    Returns:
        mean_distance (float): The mean Haversine distance between centroids in the two sets.
        median_distance (float): The median Haversine distance between centroids in the two sets.
        min_distance (float): The minimum Haversine distance between centroids in the two sets.
        max_distance (float): The maximum Haversine distance between centroids in the two sets.
    """
    if method == 'haversine':
        # Convert the centroids to numpy arrays
        latlon1 = np.array(centroids1)
        latlon2 = np.array(centroids2)
        
        # Compute all pairwise Haversine distances
        distances = haversine_array(latlon1, latlon2).flatten()  # Flatten to get a 1D array
    elif method == 'euclidean':
        distances = []
        for c1 in centroids1:
            for c2 in centroids2:
                distances.append(euclidean(c1, c2))
   
    return np.mean(distances), np.median(distances), np.min(distances), np.max(distances)


def compare_enso_phases_dbscan(df, method, eps=1.0, min_samples=5):
    """ 
    Runs DBSCAN clustering on the dataset for different ENSO phases (La Niña, El Niño, Neutral), 
    computes cluster metrics for each phase, and compares the clusters between phases.
    
    Parameters:
        df (DataFrame): The dataset containing 'lon', 'lat', and 'enso' columns.
        eps (float): The maximum distance between two samples for them to be considered as neighbors (default: 1.0).
        min_samples (int): The minimum number of samples required to form a cluster (default: 5).
    
    Returns:
        results (dict): A dictionary containing the number of clusters, average size, and centroids for each ENSO phase.
        comparisons (dict): A dictionary containing the mean, median, minimum, and maximum distances between centroids 
                            of clusters for different ENSO phases.
    """
    phases = {
        'La Niña': df[df.enso == -1],
        'El Niño': df[df.enso == 1],
        'Neutral': df[df.enso == 0]
    }

    results = {}

    # Compute DBSCAN metrics for each phase
    for phase, df in phases.items():
        clusters, _ = run_dbscan(df, method, eps=eps, min_samples=min_samples)
        metrics = compute_cluster_metrics(clusters)
        results[phase] = metrics

    # Compare clusters between phases
    comparisons = {}
    phases_list = list(phases.keys())
    for i in range(len(phases_list)):
        for j in range(i + 1, len(phases_list)):
            phase1, phase2 = phases_list[i], phases_list[j]
            mean_dist, median_dist, min_dist, max_dist = compare_clusters(results[phase1][2], results[phase2][2], method)
            comparisons[f'{phase1} vs {phase2}'] = {
                'Mean Distance': mean_dist,
                'Median Distance': median_dist,
                'Min Distance': min_dist,
                'Max Distance': max_dist
            }

    return results, comparisons


def plot_clusters(results, region):
    """ 
    Plots the number of clusters and the average cluster size for each ENSO phase in a specified region. 
    The number of clusters is displayed as a bar chart, and the average cluster size is shown as a scatter plot.
    
    Parameters:
        results (dict): A dictionary containing the number of clusters and average cluster size for each ENSO phase.
        region (str): The name of the region (e.g., "NW" or "NE/Central Pacific") where the analysis is conducted.
    """
    
    phases = list(results.keys())
    num_clusters = [results[phase][0] for phase in phases]
    avg_cluster_sizes = [results[phase][1] for phase in phases]

    fig, ax1 = plt.subplots(figsize=(10, 6))

    # Bar chart for the number of clusters
    bars = ax1.bar(phases, num_clusters, color='skyblue', alpha=0.7, label='Number of Clusters')
    ax1.set_xlabel('ENSO Phases')
    ax1.set_ylabel('Number of Clusters', color='skyblue')
    ax1.tick_params(axis='y', labelcolor='skyblue')
    add_value_labels(ax1, bars)
    
    # Line chart for the average cluster size
    ax2 = ax1.twinx()
    ax2.scatter(phases, avg_cluster_sizes, color='orange', marker='o', linestyle='-', label='Average Cluster Size')
    ax2.set_ylabel('Average Cluster Size', color='orange')
    ax2.tick_params(axis='y', labelcolor='orange')

    for i, value in enumerate(avg_cluster_sizes):
        ax2.annotate(f'{value:.2f}', 
                    xy=(phases[i], value), 
                    xytext=(8, 0), 
                    textcoords="offset points",
                    ha='left', va='center', 
                    color='orange')
    
    # Title and layout
    fig.suptitle(f'Number of Clusters and Average Cluster Size by ENSO Phase in {region} Pacific')
    fig.tight_layout()
    plt.show()

def plot_centroid_distance(comparisons, region):
    """ 
    Plots the centroid distance comparison between different ENSO phases. The distances (minimum, mean, 
    median, and maximum) between cluster centroids are visualized for each phase comparison.
    
    Parameters:
        comparisons (dict): A dictionary containing the centroid distances (min, mean, median, max) between ENSO phases.
        region (str): The name of the region (e.g., "NW" or "NE/Central Pacific") where the analysis is conducted.
    """
    
    labels = ['Min Distance', 'Mean Distance', 'Median Distance', 'Max Distance']
    
    # Create a subplot for each phase comparison
    fig, axs = plt.subplots(nrows=1, ncols=len(comparisons), figsize=(18, 6))
    
    for idx, (comparison, metrics) in enumerate(comparisons.items()):
        distances = [metrics['Min Distance'], metrics['Mean Distance'], 
                     metrics['Median Distance'], metrics['Max Distance']]
        
        bars = axs[idx].bar(labels, distances, color=['blue', 'green', 'red', 'orange'])
        axs[idx].set_title(f'Centroid Distance: {comparison}')
        axs[idx].set_ylabel('Distance (Degrees)')
        axs[idx].set_ylim(0, max(distances) * 1.2)
        add_value_labels(axs[idx], bars)
    
    fig.suptitle(f'Centroid Distance Comparisons Between ENSO Phases in {region} Pacific')
    plt.tight_layout()
    plt.show()

def plot_centroid_model(results, comparisons, region):
    """ 
    Combines the cluster metrics and centroid distance comparison into one plot. It first plots the 
    number of clusters and average cluster size for each ENSO phase, and then plots the centroid distance 
    comparisons between different ENSO phases.
    
    Parameters:
        results (dict): A dictionary containing the number of clusters and average cluster size for each ENSO phase.
        comparisons (dict): A dictionary containing the centroid distances (min, mean, median, max) between ENSO phases.
        region (str): The name of the region (e.g., "NW" or "NE/Central Pacific") where the analysis is conducted.
    """
    
    plot_clusters(results, region)
    plot_centroid_distance(comparisons, region)


def print_enso_comparison(results, comparisons):
    # Only for testing purposes
    # Print cluster numbers and average sizes
    for phase, metrics in results.items():
        print(f"Number of {phase} Clusters: {metrics[0]}")
        print(f"Average {phase} Cluster Size: {metrics[1]:.2f}")
        print()

    # Print centroid distance comparisons
    print("Centroid Distance Comparisons:")
    for comparison, metrics in comparisons.items():
        print(f"{comparison}:")
        print(f"  Mean Distance: {metrics['Mean Distance']:.2f}")
        print(f"  Median Distance: {metrics['Median Distance']:.2f}")
        print(f"  Min Distance: {metrics['Min Distance']:.2f}")
        print(f"  Max Distance: {metrics['Max Distance']:.2f}")
        print()


results, comparisons = compare_enso_phases_dbscan(jma_enso, method='euclidean')
plot_centroid_model(results, comparisons, 'NW')
print_enso_comparison(results, comparisons)


results, comparisons = compare_enso_phases_dbscan(jma_enso, method='haversine', eps=15, min_samples=10)
plot_centroid_model(results, comparisons, 'NW')
print_enso_comparison(results, comparisons)








results, comparisons = compare_enso_phases_dbscan(nhc_enso, method='euclidean')
plot_centroid_model(results, comparisons, 'Central and NE')
print_enso_comparison(results, comparisons)


results, comparisons = compare_enso_phases_dbscan(nhc_enso, method='haversine', eps=10, min_samples=5)
plot_centroid_model(results, comparisons, 'Central and NE')
print_enso_comparison(results, comparisons)














def custom_wind_mean(series):
    """ 
    Computes the mean wind speed, excluding non-valid wind data (i.e., values less than or equal to 0).
    
    Parameters:
        series (Series): A Pandas Series containing wind speed values.
    Returns:
        float: The mean wind speed, or NaN if no valid values are present.
    """
    filtered_series = series[series > 0]
    if len(filtered_series) > 0:
        return filtered_series.mean()
    else:
        return np.nan

def custom_pressure_mean(series):
    """ 
    Computes the mean pressure, excluding non-valid pressure data (i.e., values less than or equal to 0).
    
    Parameters:
        series (Series): A Pandas Series containing pressure values.
    Returns:
        float: The mean pressure, or NaN if no valid values are present.
    """
    filtered_series = series[series > 0]
    if len(filtered_series) > 0:
        return filtered_series.mean()
    else:
        return np.nan

def combine_date_month(df):
    """ 
    Combines the 'year' and 'month' columns into a single 'date' column in YYYY-MM format, and sets this 
    as the index. The original 'year', 'month', and temporary 'date' columns are dropped.
    
    Parameters:
        df (DataFrame): A Pandas DataFrame containing 'year' and 'month' columns.
    Returns:
        DataFrame: The updated DataFrame with the combined 'date' column as the index.
    """
    df['date'] = [f'{df.year[i]}-0{df.month[i]}' if len(str(df.month[i])) == 1 else f'{df.year[i]}-{df.month[i]}' for i in df.index]
    
    df.date = pd.to_datetime(df.date)
    df.index = pd.Index(df.date)

    df = df.drop(columns=['year', 'month', 'date'])
    return df

def prepare_statistical_dataframe(df1, corr_period):
    """ 
    Aggregates the count of tropical depressions (TDs), mean pressure, and mean wind per month, 
    and merges the result with ONI (Oceanic Niño Index) monthly data. 
    
    Parameters:
        df1 (DataFrame): A DataFrame containing tropical depression data.
        corr_period (str): The correlation period ('m' for monthly, 'y' for yearly). 
    Returns:
        DataFrame: A DataFrame with aggregated statistics and merged ONI data.
    """

    if corr_period == 'm':
        df2 = oni_table
        query = [df1.index.year, df1.index.month]  # Group by year and month
    else:
        df2 = pd.DataFrame(enso_phase)
        query = [df1.index.year]  # Group by year only
    
    # Group by year and month, then aggregate
    df1 = df1.groupby(query).agg({
        'name': lambda x: list(pd.Series(x).unique()),  # List of unique storm names per month
        'min_pressure_mBar': custom_pressure_mean,  
        'max_wind_kn': custom_wind_mean,
        'lat': 'mean',
        'lon': 'mean',
    }).rename(columns={
        'name': 'unique_names',  # Store the list of unique storm names in 'unique_names'
        'min_pressure_mBar': 'average_min_pressure', 
        'max_wind_kn': 'average_max_wind',
        'lat': 'average_lat',
        'lon': 'average_lon'
    })

    # Count the number of unique names (storms) per month
    df1['frequency'] = df1['unique_names'].apply(len)

    # Reset the index and merge with ONI data if required
    if corr_period == 'm':
        df1.index.names = ['year', 'month']
        df1 = df1.reset_index()
        df1 = combine_date_month(df1)  # Combine year and month into a date column
    
    return pd.merge(df1, df2, on='date')  # Merge with ONI data

def perform_correlation(df, corr_period='m', corr_type='pearson', is_text_required=False):
    """ 
    Calculates the correlation between SST anomaly (from ONI) and various tropical depression variables, 
    such as frequency, pressure, wind speed, latitude, and longitude, using the specified correlation type.
    
    Parameters:
        df (DataFrame): A DataFrame with tropical depression statistics and ONI data.
        corr_period (str): The correlation period ('m' for monthly, 'y' for yearly).
        corr_type (str): The type of correlation to perform ('pearson' or 'spearman').
        is_text_required (bool): If True, returns the correlation results as a formatted text string. 
                                 If False, returns the results as a dictionary.
    Returns:
        dict or str: A dictionary of correlation results, or a formatted text string if is_text_required is True.
    """
    df = prepare_statistical_dataframe(df, corr_period)

    correlation = {
        'pearson': pearsonr,
        'spearman': spearmanr
    }
    if corr_period == 'm':
        # shifting the anomaly to align with the assumption that previous year anomaly affects this year TD season
        df['sst_anomaly'] = df['sst_anomaly'].shift(freq=pd.DateOffset(months=6))
        target_col = 'sst_anomaly'
    else:
        target_col = 'enso'
    
    df = df.dropna()

    output = {
            'corr_type': corr_type,
            'corr_period': corr_period,
            'Frequency': correlation[corr_type](df[target_col], df['frequency'])[0],
            'Pressure': correlation[corr_type](df[target_col], df['average_min_pressure'])[0],
            'Wind': correlation[corr_type](df[target_col], df['average_max_wind'])[0],
            'Latitude': correlation[corr_type](df[target_col], df['average_lat'])[0],
            'Longitude': correlation[corr_type](df[target_col], df['average_lon'])[0]
        }
    
    if not is_text_required:
        return output
    
    return (f"{corr_type[0].upper() + corr_type[1:]} Correlation\n"
            f"Frequency: {output['Frequency']}\n"
            f"Pressure: {output['Pressure']}\n"
            f"Wind: {output['Wind']}\n"
            f"Lat: {output['Latitude']}\n"
            f"Lon: {output['Longitude']}")

def plot_correlations(dfs=(jma_enso, nhc_enso), corr_period='m', corr_type='pearson'):
    """ 
    Calculates and plots correlation heatmaps for tropical depression variables and SST anomaly 
    for different ENSO phases (El Niño, La Niña, Neutral) in the Pacific Ocean, using Pearson or Spearman correlation.
    
    Parameters:
        dfs (tuple): Dataframes to correlate and compare
        corr_period (str): The correlation period ('m' for monthly, 'y' for yearly).
        corr_type (str): The type of correlation to plot ('pearson' or 'spearman').
    Returns:
        None: Displays the heatmap plots.
    """
    ocean_area = get_ocean_area_label()
    
    correlations = [perform_correlation(df, corr_period=corr_period, corr_type=corr_type) for df in dfs]   
    
    periods = {
        'm': 'Monthly',
        'y': 'Yearly'
    }

    fig, axs = plt.subplots(1, 2, figsize=(12, 6))
    
    for i in range(2):
        data = correlations[i]
        period = periods[data['corr_period']]
        name = data['corr_type'][0].upper() + data['corr_type'][1:]

        # removing unwanted keys
        del data['corr_period']
        del data['corr_type']
        
        variables = [x for x in data.keys()]
        correlation_values = [x for x in data.values()]
        df = pd.DataFrame(correlation_values, index=variables, columns=[f'{name} Correlation'])
        sns.heatmap(df, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5, ax=axs[i], cbar=[True if i == 0 else False][0])
        axs[i].set_title(f'{name} {period} Correlation Heatmap for {ocean_area[i]} Pacific')
        
    plt.tight_layout()
    plt.show()


print(perform_correlation(nhc_enso, corr_period='m', corr_type='spearman', is_text_required=True))


plot_correlations(corr_period='m', corr_type='pearson')











def custom_pressure_min(series):
    """ 
    Computes the minimum pressure, excluding non-valid pressure data (i.e., values less than or equal to 0).
    
    Parameters:
        series (Series): A Pandas Series containing pressure values.
    Returns:
        float: The minimum pressure, or NaN if no valid values are present.
    """
    filtered_series = series[series > 0]
    if len(filtered_series) > 0:
        return filtered_series.min()
    else:
        return np.nan

def custom_wind_max(series):
    """ 
    Computes the maximum wind speed, excluding non-valid wind data (i.e., values less than or equal to 0).
    
    Parameters:
        series (Series): A Pandas Series containing wind speed values.  
    Returns:
        float: The maximum wind speed, or NaN if no valid values are present.
    """
    filtered_series = series[series > 0]
    if len(filtered_series) > 0:
        return filtered_series.max()
    else:
        return np.nan
    

def calculate_duration(df):
    """ 
    Calculates the duration of a tropical depression (TD) based on the index of the dataframe. 
    The duration is the difference between the maximum and minimum index values.
    
    Parameters:
        df (DataFrame): A Pandas DataFrame with the index representing time.   
    Returns:
        Timedelta: The duration of the tropical depression.
    """
    return df.index.max() - df.index.min()


def aggreagate_duration(df):
    """ 
    Aggregates tropical depression data by calculating the duration, minimum pressure, and maximum wind speed 
    for each tropical depression. Also includes the corresponding ENSO phase for each depression.
    
    Parameters:
        df (DataFrame): A DataFrame containing tropical depression data, including columns for pressure, wind, and ENSO phase.
    Returns:
        DataFrame: A DataFrame with aggregated tropical depression data, including duration, minimum pressure, 
                   maximum wind, and ENSO phase.
    """
    df = df.copy()
    df['duration'] = pd.Series()
    
    df = df.groupby([df.index.year, df.name]).agg({
        'duration':  calculate_duration,
        'min_pressure_mBar': custom_pressure_min,
        'max_wind_kn': custom_wind_max,
        'enso': 'min'
    })

    df['duration'] = df['duration'].dt.total_seconds() / 3600
    
    df = df.reset_index()
    df.index = pd.Index(df.date)
    df = df.drop(columns='date')

    df = df.dropna()

    return df

def ttest(df, phases_arr=(1, -1), test='w', equal_var=False):
    """ 
    Performs a t-test to compare tropical depression metrics (wind intensity, pressure, or duration) between two 
    specified ENSO phases. Optionally plots the result.
    
    Parameters:
        df (DataFrame): A DataFrame with aggregated tropical depression data, including duration, pressure, wind, and ENSO phase.
        phases_arr (tuple): A tuple of two ENSO phases to compare (default: (1, -1) for El Niño vs La Niña).
        test (str): The metric to test ('w' for wind intensity, 'p' for pressure, 'd' for duration).
        equal_var (bool): Whether to assume equal variance for the t-test (default: False).
    Returns:
        None: Prints the t-test result and optionally plots it.
    """
    phases = get_phase_names()
    
    test_type_mapper = {
        'w': 'Wind Intensity',
        'p': 'Pressure Intensity',
        'd': 'Duration',
    }
    
    test_mapper = {
        'w': 'max_wind_kn',
        'p': 'min_pressure_mBar',
        'd': 'duration',
    }

    df = aggreagate_duration(df)
  
    df1 = df[df.enso == phases_arr[0]]
    df2 = df[df.enso == phases_arr[1]]
    
    t_stat, p_value = ttest_ind(df1[test_mapper[test]], df2[test_mapper[test]], equal_var=equal_var)

    print(f"T-test for {test_type_mapper[test]} ({phases[phases_arr[0]]} vs {phases[phases_arr[1]]}): t-stat = {t_stat}, p-value = {p_value}")


ttest(jma_enso, (1, -1))
ttest(jma_enso, (1, 0))
ttest(jma_enso, (-1, 0))





ttest(jma_enso, (1, -1), 'p')
ttest(jma_enso, (1, 0), 'p')
ttest(jma_enso, (-1, 0), 'p')





ttest(jma_enso, (1, -1), 'd')
ttest(jma_enso, (1, 0), 'd')
ttest(jma_enso, (-1, 0), 'd')





ttest(nhc_enso, (1, -1))
ttest(nhc_enso, (1, 0))
ttest(nhc_enso, (-1, 0))





ttest(nhc_enso, (1, -1), 'p')
ttest(nhc_enso, (1, 0), 'p')
ttest(nhc_enso, (-1, 0), 'p')





ttest(nhc_enso, (1, -1), 'd')
ttest(nhc_enso, (1, 0), 'd')
ttest(nhc_enso, (-1, 0), 'd')




































