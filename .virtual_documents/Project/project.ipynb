get_ipython().run_line_magic("matplotlib", " inline")


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import gaussian_kde, pearsonr, spearmanr
from scipy.spatial.distance import euclidean
from sklearn.cluster import DBSCAN

from plotting import plot_equatorial_pacific, get_dataframe





plot_equatorial_pacific(path='data/csv_ready/elnino_2015.csv', cond_name='El Niño Period', vmin=20, vmax=35)


plot_equatorial_pacific('data/csv_ready/neutral_2012.csv', 'Neutral Period', vmin=20, vmax=35)


plot_equatorial_pacific('data/csv_ready/lanina_2010.csv', 'La Niña Period', vmin=20, vmax=35)


la_nina = get_dataframe('data/csv_ready/lanina_2010.csv')
neutral = get_dataframe('data/csv_ready/neutral_2012.csv')
el_nino = get_dataframe('data/csv_ready/elnino_2015.csv')

dataframes = [el_nino, neutral, la_nina]
colors = ['r', 'g', 'b']
x = ['October', 'November', 'December', 'January']
labels = ['El Niño', 'Neutral', 'La Niña']
for i, df in enumerate(dataframes):
    sst = df.groupby(df.index).sst.mean()
    plt.plot(x, sst, c=colors[i], label=labels[i])

plt.ylim(26, 29)

plt.legend()
plt.xlabel('Months')
plt.ylabel('SST in deg C')
plt.title('Difference in the SST between El Niño, La Niña and Neutral Periods')
plt.show()








oni_table = pd.read_csv('data/csv_ready/oni_table.csv', index_col=0)
oni_table.index = pd.to_datetime(oni_table.index)
enso_phase = oni_table.groupby(oni_table.index.year)['enso'].apply(lambda x: x.unique()[0])

jma = pd.read_csv('data/csv_ready/jma_td.csv', index_col=0)
jma.index = pd.to_datetime(jma.index)
frequency_jma = jma.groupby(jma.index.year)['name'].nunique()
frequency_jma = pd.merge(frequency_jma, enso_phase, on='date')
frequency_jma.columns = ['frequency', 'enso']

nhc = pd.read_csv('data/csv_ready/ne_pacific_td.csv', index_col=0)
nhc.index = pd.to_datetime(nhc.index)
frequency_nhc = nhc.groupby(nhc.index.year)['name'].nunique()
frequency_nhc = pd.merge(frequency_nhc,enso_phase, on='date')
frequency_nhc.columns = ['frequency', 'enso']

nhc_cp = nhc[nhc.basin == 'CP']
frequency_nhc_cp = nhc_cp.groupby(nhc_cp.index.year)['name'].nunique()
frequency_nhc_cp = pd.merge(frequency_nhc_cp,enso_phase, on='date')
frequency_nhc_cp.columns = ['frequency', 'enso']

nhc_ep = nhc[nhc.basin == 'EP']
frequency_nhc_ep = nhc_ep.groupby(nhc_ep.index.year)['name'].nunique()
frequency_nhc_ep = pd.merge(frequency_nhc_ep,enso_phase, on='date')
frequency_nhc_ep.columns = ['frequency', 'enso']


colors = {-1: 'blue', 0: 'green', 1: 'red'}
labels = ['La Niña', 'Neutral', 'El Niño']

frequency_tables = [
    ('NW', frequency_jma), 
    ('Central', frequency_nhc_cp), 
    ('NE', frequency_nhc_ep)]

fig, axs = plt.subplots(1, 3, figsize=(30, 8))

for i, table in enumerate(frequency_tables):
    for year, freq, enso in zip(table[1].index, table[1].frequency, table[1].enso):
        axs[i].bar(year, freq, color=colors[enso])

    handles = [plt.Rectangle((0,0),1,1, color=colors[enso]) for enso in colors]
    axs[i].legend(handles, labels, title='ENSO Phase', loc='upper left')
    axs[i].set_title(f'Frequency of Tropical Depressions, originating in the {table[0]} Pacific, by Year')
    axs[i].set_xlabel('Year')
    axs[i].set_ylabel('Number of Tropical Depressions')
    axs[i].set_xlim(1950, 2024)
    axs[i].set_ylim(0, 37)

plt.show()


def add_value_labels(ax, bars):
    for bar in bars:
        height = bar.get_height()
        ax.annotate(f'{height:.2f}',  # Display the height value with 2 decimal places
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3),  # Offset the text slightly above the bar
                    textcoords="offset points",
                    ha='center', va='bottom')

means_jma = [x for x in frequency_jma.groupby(['enso']).frequency.mean()]
means_nhc = [x for x in frequency_nhc.groupby(['enso']).frequency.mean()]
x = np.arange(len(labels))
width = 0.20

fig, ax = plt.subplots(figsize=(10, 8))

bars1 = ax.bar(x - width/2, means_jma, width, label='NW Pacific (JMA)', color='blue')
bars2 = ax.bar(x + width/2, means_nhc, width, label='Central/NE Pacific (NHC)', color='orange')

ax.set_xlabel('ENSO Phase')
ax.set_ylabel('Mean Frequency of Tropical Depressions')
ax.set_title('Mean Frequency of Tropical Depressions by ENSO Phase')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

add_value_labels(ax, bars1)
add_value_labels(ax, bars2)

plt.show()





# Grouping by year and finding max wind and min press
jma_max_wind = jma.groupby([jma.index.year]).max_wind_kn.max()
nhc_max_wind = nhc.groupby([nhc.index.year]).max_wind_kn.max()

jma_min_press = jma.groupby([jma.index.year]).min_pressure_mBar.min()
nhc_min_press = nhc.groupby([nhc.index.year]).min_pressure_mBar.min()

jma_max_wind = pd.merge(jma_max_wind, enso_phase, on='date')
jma_max_wind.max_wind_kn = jma_max_wind.max_wind_kn.apply(lambda x: None if x == 0 else x)
jma_max_wind = jma_max_wind.dropna()
nhc_max_wind = pd.merge(nhc_max_wind, enso_phase, on='date')

jma_min_press = pd.merge(jma_min_press, enso_phase, on='date')
nhc_min_press = pd.merge(nhc_min_press, enso_phase, on='date')
nhc_min_press.min_pressure_mBar = nhc_min_press.min_pressure_mBar.apply(lambda x: None if x < 0 else x)
nhc_min_press = nhc_min_press.dropna()


# statistics
def extract_stats(df):
    df = df.groupby(['enso']).describe().T
    df = df.reset_index()
    df = df.drop(columns='level_0')
    df = df.pivot_table(columns='level_1')

    return df
    
array_of_data = [jma_max_wind, nhc_max_wind, jma_min_press, nhc_min_press]
jma_max_wind_stats = extract_stats(jma_max_wind)
nhc_max_wind_stats = extract_stats(nhc_max_wind)
jma_min_press_stats = extract_stats(jma_min_press)
nhc_min_press_stats = extract_stats(nhc_min_press)


# function to plot the boxplot and tables
ocean_area = ['NW', 'Central and NE']
def plot_boxplot_and_table(dataset_array, tables_array, col_name, title, ylim=None):
    
    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 12))
    
    for i, df in enumerate(dataset_array):
        axs[0][i].boxplot([df[df['enso'] == -1][col_name],
                         df[df['enso'] == 0][col_name],
                         df[df['enso'] == 1][col_name]],
                         labels=labels)
        axs[0][i].set_title(f'{title} by ENSO Phase for {ocean_area[i]} Pacific')
        axs[0][i].set_xlabel('ENSO Phase')
        axs[0][i].set_ylabel(title)
        if not ylim is None:
            axs[0][i].set_ylim(ylim)
    
    for i, dt in enumerate(tables_array):
        axs[1][i].axis('tight')
        axs[1][i].axis('off')
        table = axs[1][i].table(cellText=dt.values.round(1),
                     colLabels=dt.columns,
                     rowLabels=labels,
                     cellLoc='center', loc='center')
    
    plt.tight_layout()
    plt.show()


# Boxplot for Maximum Wind Speed
dataset_boxplot = [jma_max_wind, nhc_max_wind]
dataset_table = [jma_max_wind_stats, nhc_max_wind_stats]

plot_boxplot_and_table(dataset_boxplot, dataset_table, 'max_wind_kn', 'Maximum Wind Speed', ylim=(70, 190))





# Boxplot for Minimum Central Pressure
dataset_boxplot = [jma_min_press, nhc_min_press]
dataset_table = [jma_min_press_stats, nhc_min_press_stats]

plot_boxplot_and_table(dataset_boxplot, dataset_table, 'min_pressure_mBar', 'Minimum Central Pressure (mBar)', ylim=(865, 975))





enso_phase_dt = enso_phase.copy()
enso_phase_dt.index = pd.to_datetime(enso_phase.index.astype(str))

merged = pd.merge(jma, enso_phase_dt, left_on=jma.index.year, right_on=enso_phase_dt.index.year, how='left')
merged = merged.set_index(jma.index)
jma_enso = merged.drop(columns='key_0')

merged = pd.merge(nhc, enso_phase_dt, left_on=nhc.index.year, right_on=enso_phase_dt.index.year, how='left')
merged = merged.set_index(nhc.index)
nhc_enso = merged.drop(columns='key_0')

gdf = pd.read_csv('data/csv_ready/gdf_pacific.csv')


cmaps = {-1: 'Blues', 0: 'Greens', 1: 'Reds'}
phases = {-1: 'La Niña', 0: 'Neutral', 1: 'El Niño'}

def plot_td_density():
    """ the function plots the density of TDs for different phases of ENSO accross North PAcific Ocean """
    datasets = [jma_enso, nhc_enso]
    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(20 * 3, 8))

    for idx, i in enumerate(range(-1, 2, 1)):
        for df in datasets:
            subset = df[df.enso == i]  
            sns.kdeplot(x=subset['lon'], y=subset['lat'], fill=True, cmap=cmaps[i], bw_adjust=0.8, ax=axs[idx])

        axs[idx].scatter(gdf.lon, gdf.lat, s=0.5, color='black')
        
        x_tick = np.arange(100, 300, 10)
        x_label = [f'{x}°E' if x <= 180 else f'{360 - x}°W' for x in x_tick]
        y_tick = np.arange(-20, 70, 10)
        y_label = [f'{np.abs(x)}°S' if x < 0 else f'{np.abs(x)}°N' for x in y_tick]
        axs[idx].set_xticks(ticks=x_tick)
        axs[idx].set_xticklabels(labels=x_label)
        axs[idx].set_yticks(ticks=y_tick)
        axs[idx].set_yticklabels(labels=y_label)
        
        axs[idx].set_title(f'Density of Tropical Depressions for {phases[i]} phase')
        axs[idx].set_xlabel('Longitude')
        axs[idx].set_ylabel('Latitude')
        
    plt.tight_layout()
    plt.show()

def compute_kde_values(df, phase, gridsize=100):
    """ computes KDE values for each phase and region (NW Pacific and NE/Central Pacific)"""
    subset = df[df.enso == phase]
    kde = gaussian_kde(np.vstack([subset['lon'], subset['lat']]))
    lon_min, lon_max = 100, 300
    lat_min, lat_max = -20, 70
    lon_grid, lat_grid = np.linspace(lon_min, lon_max, gridsize), np.linspace(lat_min, lat_max, gridsize)
    lon_grid, lat_grid = np.meshgrid(lon_grid, lat_grid)
    kde_values = kde(np.vstack([lon_grid.ravel(), lat_grid.ravel()])).reshape(gridsize, gridsize)
    return lon_grid, lat_grid, kde_values

def plot_td_density_difference():
    """ the function plots the density difference of TDs for different phases of ENSO accross North PAcific Ocean """
    kde_values_jma = {phase: compute_kde_values(jma_enso, phase)[2] for phase in range(-1, 2)}
    kde_values_nhc = {phase: compute_kde_values(nhc_enso, phase)[2] for phase in range(-1, 2)}

    # Subtract KDE values to create difference maps for each region
    diff_maps_jma = {
        'El Niño - La Niña (NW Pacific)': kde_values_jma[1] - kde_values_jma[-1],
        'Neutral - La Niña (NW Pacific)': kde_values_jma[0] - kde_values_jma[-1],
        'Neutral - El Niño (NW Pacific)': kde_values_jma[0] - kde_values_jma[1]
    }
    
    diff_maps_nhc = {
        'El Niño - La Niña (NE/Central Pacific)': kde_values_nhc[1] - kde_values_nhc[-1],
        'Neutral - La Niña (NE/Central Pacific)': kde_values_nhc[0] - kde_values_nhc[-1],
        'Neutral - El Niño (NE/Central Pacific)': kde_values_nhc[0] - kde_values_nhc[1]
    }

    fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(20, 12))
    
    for i, diff_dt in enumerate([diff_maps_jma, diff_maps_nhc]):
        for idx, (title, diff_map) in enumerate(diff_dt.items()):
            im = axs[i, idx].imshow(diff_map, extent=[100, 300, -20, 70], origin='lower', cmap='coolwarm')
            axs[i, idx].set_title(title)
            axs[i, idx].scatter(gdf.lon, gdf.lat, s=0.5, color='black')
            
            x_tick = np.arange(100, 300, 25)
            x_label = [f'{x}°E' if x <= 180 else f'{360 - x}°W' for x in x_tick]
            y_tick = np.arange(-20, 70, 20)
            y_label = [f'{np.abs(x)}°S' if x < 0 else f'{np.abs(x)}°N' for x in y_tick]
            axs[i, idx].set_xticks(ticks=x_tick)
            axs[i, idx].set_xticklabels(labels=x_label)
            axs[i, idx].set_yticks(ticks=y_tick)
            axs[i, idx].set_yticklabels(labels=y_label)
            
            axs[i, idx].set_xlabel('Longitude')
            axs[i, idx].set_ylabel('Latitude')
    
    plt.tight_layout()
    plt.show()


plot_td_density()





plot_td_density_difference()





def run_dbscan(df, eps=1.0, min_samples=5):
    coords = df[['lon', 'lat']].values
    db = DBSCAN(eps=eps, min_samples=min_samples).fit(coords)
    labels = db.labels_
    unique_labels = set(labels)
    clusters = [coords[labels == label] for label in unique_labels if label != -1]  # Exclude noise (-1)
    return clusters, labels

def compute_cluster_metrics(clusters):
    num_clusters = len(clusters)
    cluster_sizes = [len(cluster) for cluster in clusters]
    average_size = np.mean(cluster_sizes)
    centroids = [np.mean(cluster, axis=0) for cluster in clusters]
    return num_clusters, average_size, centroids

def compare_clusters(centroids1, centroids2):
    distances = []
    for c1 in centroids1:
        for c2 in centroids2:
            distances.append(euclidean(c1, c2))
    return np.mean(distances), np.median(distances), np.min(distances), np.max(distances)

def compare_enso_phases_dbscan(df, eps=1.0, min_samples=5):
    phases = {
        'La Niña': df[df.enso == -1],
        'El Niño': df[df.enso == 1],
        'Neutral': df[df.enso == 0]
    }

    results = {}

    # Compute DBSCAN metrics for each phase
    for phase, df in phases.items():
        clusters, _ = run_dbscan(df, eps=eps, min_samples=min_samples)
        metrics = compute_cluster_metrics(clusters)
        results[phase] = metrics

    # Compare clusters between phases
    comparisons = {}
    phases_list = list(phases.keys())
    for i in range(len(phases_list)):
        for j in range(i + 1, len(phases_list)):
            phase1, phase2 = phases_list[i], phases_list[j]
            mean_dist, median_dist, min_dist, max_dist = compare_clusters(results[phase1][2], results[phase2][2])
            comparisons[f'{phase1} vs {phase2}'] = {
                'Mean Distance': mean_dist,
                'Median Distance': median_dist,
                'Min Distance': min_dist,
                'Max Distance': max_dist
            }

    return results, comparisons


def plot_clusters(results, comparisons, region):
    """Plots the number of clusters with average cluster size for each ENSO phase."""
    
    phases = list(results.keys())
    num_clusters = [results[phase][0] for phase in phases]
    avg_cluster_sizes = [results[phase][1] for phase in phases]

    fig, ax1 = plt.subplots(figsize=(10, 6))

    # Bar chart for the number of clusters
    bars = ax1.bar(phases, num_clusters, color='skyblue', alpha=0.7, label='Number of Clusters')
    ax1.set_xlabel('ENSO Phases')
    ax1.set_ylabel('Number of Clusters', color='skyblue')
    ax1.tick_params(axis='y', labelcolor='skyblue')
    add_value_labels(ax1, bars)
    
    # Line chart for the average cluster size
    ax2 = ax1.twinx()
    ax2.scatter(phases, avg_cluster_sizes, color='orange', marker='o', linestyle='-', label='Average Cluster Size')
    ax2.set_ylabel('Average Cluster Size', color='orange')
    ax2.tick_params(axis='y', labelcolor='orange')

    for i, value in enumerate(avg_cluster_sizes):
        ax2.annotate(f'{value:.2f}', 
                    xy=(phases[i], value), 
                    xytext=(8, 0), 
                    textcoords="offset points",
                    ha='left', va='center', 
                    color='orange')
    
    # Title and layout
    fig.suptitle(f'Number of Clusters and Average Cluster Size by ENSO Phase in {region} Pacific')
    fig.tight_layout()
    plt.show()

def plot_centroid_distance(comparisons, region):
    """Plots the centroid distance comparison between ENSO phases individually."""
    
    labels = ['Min Distance', 'Mean Distance', 'Median Distance', 'Max Distance']
    
    # Create a subplot for each phase comparison
    fig, axs = plt.subplots(nrows=1, ncols=len(comparisons), figsize=(18, 6))
    
    for idx, (comparison, metrics) in enumerate(comparisons.items()):
        distances = [metrics['Min Distance'], metrics['Mean Distance'], 
                     metrics['Median Distance'], metrics['Max Distance']]
        
        bars = axs[idx].bar(labels, distances, color=['blue', 'green', 'red', 'orange'])
        axs[idx].set_title(f'Centroid Distance: {comparison}')
        axs[idx].set_ylabel('Distance (Degrees)')
        axs[idx].set_ylim(0, max(distances) * 1.2)
        add_value_labels(axs[idx], bars)
    
    fig.suptitle(f'Centroid Distance Comparisons Between ENSO Phases in {region} Pacific')
    plt.tight_layout()
    plt.show()

def plot_centroid_model(results, comparisons, region):
    """Combines the cluster and centroid distance plots into one function."""
    
    plot_clusters(results, comparisons, region)
    plot_centroid_distance(comparisons, region)


def print_enso_comparison(results, comparisons):
    # Print cluster numbers and average sizes
    for phase, metrics in results.items():
        print(f"Number of {phase} Clusters: {metrics[0]}")
        print(f"Average {phase} Cluster Size: {metrics[1]:.2f}")
        print()

    # Print centroid distance comparisons
    print("Centroid Distance Comparisons:")
    for comparison, metrics in comparisons.items():
        print(f"{comparison}:")
        print(f"  Mean Distance: {metrics['Mean Distance']:.2f}")
        print(f"  Median Distance: {metrics['Median Distance']:.2f}")
        print(f"  Min Distance: {metrics['Min Distance']:.2f}")
        print(f"  Max Distance: {metrics['Max Distance']:.2f}")
        print()


results, comparisons = compare_enso_phases_dbscan(jma_enso)
plot_centroid_model(results, comparisons, 'NW')

# numerical representation of the results
# print_enso_comparison(results, comparisons)





results, comparisons = compare_enso_phases_dbscan(nhc_enso)
plot_centroid_model(results, comparisons, 'Central and NE')

# numerical representation of the results
# print_enso_comparison(results, comparisons)





def custom_wind_mean(series):
    """ the function does not aggregate non-valid wind """
    filtered_series = series[series > 0]
    if len(filtered_series) > 0:
        return filtered_series.mean()
    else:
        return np.nan

def custom_pressure_mean(series):
    """ the function does not aggregate non-valid pressure """
    filtered_series = series[series > 0]
    if len(filtered_series) > 0:
        return filtered_series.mean()
    else:
        return np.nan

def combine_date_month(df):
    df['date'] = [f'{df.year[i]}-0{df.month[i]}' if len(str(df.month[i])) == 1 else f'{df.year[i]}-{df.month[i]}' for i in df.index]
    
    df.date = pd.to_datetime(df.date)
    df.index = pd.Index(df.date)

    df = df.drop(columns=['year', 'month', 'date'])
    return df

def prepare_statistical_dataframe(df1, df2=oni_table, corr_period):
    """ the function aggregates count/mena pressure and mean wind per month and merges with ONI monthly data """

    if 'category' in df1:
        counted = 'category'
    else:
        counted = 'type_of_depression'
    
    df1 = df1.groupby([df1.index.year, df1.index.month]).agg({
        counted: 'count',
        'min_pressure_mBar': custom_pressure_mean,  
        'max_wind_kn': custom_wind_mean,
        'lat': 'mean',
        'lon': 'mean',
    }).rename(columns={
        counted: 'frequency', 
        'min_pressure_mBar': 'average_min_pressure', 
        'max_wind_kn': 'average_max_wind',
        'lat': 'average_lat',
        'lon': 'average_lon'
    })
    df1.index.names = ['year', 'month']
    df1 = df1.reset_index()
    df1 = combine_date_month(df1) 
        
    return pd.merge(df1, df2, on='date')

def perform_correlation(df, corr_period='m', corr_type='pearson'):
    
    df = prepare_statistical_dataframe(df, corr_period)
    
    correlation = {
        'pearson': pearsonr,
        'spearman': spearmanr
    }
    if corr_period == 'm':
        # shifting the anomaly to allign with the assumption that previous year anomally affects this year TD season
        df['sst_anomaly'] = df['sst_anomaly'].shift(freq=pd.DateOffset(months=6))
        
    df = df.dropna()

    frequency = correlation[corr_type](df['sst_anomaly'], df['frequency'])[0]
    pressure = correlation[corr_type](df['sst_anomaly'], df['average_min_pressure'])[0]
    wind = correlation[corr_type](df['sst_anomaly'], df['average_max_wind'])[0]
    latitude = correlation[corr_type](df['sst_anomaly'], df['average_lat'])[0]
    longitude = correlation[corr_type](df['sst_anomaly'], df['average_lon'])[0]
    
    return f'{corr_type[0].upper() + corr_type[1:]} Correlation\nFrequency: {frequency}\nPressure: {pressure}\nWind: {wind}\nLat: {latitude}\nLon: {longitude}'





print(perform_correlation(jma_enso))


print(perform_correlation(jma_enso, 'spearman'))


print(perform_correlation(nhc_enso))


print(perform_correlation(nhc_enso, 'spearman'))



